{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(r'train.csv',index_col=0)\n",
    "test_data  = pd.read_csv(r'test.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.6 GiB for an array with shape (597, 26296946) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leoau\\Documents\\Canada\\Lighthouse Data Science Course\\Week 22\\predict-student-performance-from-game-play\\XGBoost Classification Assignment.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leoau/Documents/Canada/Lighthouse%20Data%20Science%20Course/Week%2022/predict-student-performance-from-game-play/XGBoost%20Classification%20Assignment.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y \u001b[39m=\u001b[39m test_data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoau/Documents/Canada/Lighthouse%20Data%20Science%20Course/Week%2022/predict-student-performance-from-game-play/XGBoost%20Classification%20Assignment.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Convert categorical columns to numeric using one-hot encoding\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/leoau/Documents/Canada/Lighthouse%20Data%20Science%20Course/Week%2022/predict-student-performance-from-game-play/XGBoost%20Classification%20Assignment.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mget_dummies(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoau/Documents/Canada/Lighthouse%20Data%20Science%20Course/Week%2022/predict-student-performance-from-game-play/XGBoost%20Classification%20Assignment.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Split the data into training and testing sets (adjust test_size and random_state as needed)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoau/Documents/Canada/Lighthouse%20Data%20Science%20Course/Week%2022/predict-student-performance-from-game-play/XGBoost%20Classification%20Assignment.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\encoding.py:209\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     with_dummies \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m col, pre, sep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_to_encode\u001b[39m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    208\u001b[0m     \u001b[39m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     dummy \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    210\u001b[0m         col[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    211\u001b[0m         prefix\u001b[39m=\u001b[39;49mpre,\n\u001b[0;32m    212\u001b[0m         prefix_sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m    213\u001b[0m         dummy_na\u001b[39m=\u001b[39;49mdummy_na,\n\u001b[0;32m    214\u001b[0m         sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[0;32m    215\u001b[0m         drop_first\u001b[39m=\u001b[39;49mdrop_first,\n\u001b[0;32m    216\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    217\u001b[0m     )\n\u001b[0;32m    218\u001b[0m     with_dummies\u001b[39m.\u001b[39mappend(dummy)\n\u001b[0;32m    219\u001b[0m result \u001b[39m=\u001b[39m concat(with_dummies, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\encoding.py:330\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     eye_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbool_\n\u001b[1;32m--> 330\u001b[0m dummy_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(number_of_cols, dtype\u001b[39m=\u001b[39;49meye_dtype)\u001b[39m.\u001b[39;49mtake(codes, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mT\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    333\u001b[0m     \u001b[39m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     dummy_mat[codes \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.6 GiB for an array with shape (597, 26296946) and data type bool"
     ]
    }
   ],
   "source": [
    "# Drop any columns that may not be relevant for classification or have unique identifiers\n",
    "# Adjust this according to your specific needs and the columns you don't want to include\n",
    "columns_to_drop = ['fqid', 'room_fqid', 'text_fqid']\n",
    "data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data\n",
    "y = test_data\n",
    "\n",
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets (adjust test_size and random_state as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'session_id': X_test['session_id'],  # Assuming 'session_id' column is present in your test data\n",
    "    'correct': y_pred  # Assuming 'correct' is the predicted label (0 or 1)\n",
    "})\n",
    "\n",
    "# Convert the session_id and question number pair into the required format\n",
    "submission_df['session_id'] = submission_df['session_id'] + '_q' + submission_df.groupby('session_id').cumcount().add(1).astype(str)\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
